import matplotlib.pyplot as plt

all_train_loss_unet = [0.4653328687355325, 0.3391247327263291, 0.28124898490873546, 0.2384050974773394, 0.21460538568931656, 0.19402223055225773, 0.1764349928377448, 0.17120633661948345, 0.16936484714214867, 0.16624193150248076, 0.16440280023458842, 0.16330491786671653, 0.16213499714393872, 0.16264776341818474, 0.16211088943118984, 0.16160620451980345, 0.16231327549227187, 0.1619700767804642, 0.16073424857411836, 0.1615576752637689]
all_val_loss_unet = [0.4164057870705922, 0.3339264017564279, 0.8013229138321347, 0.2698366691668828, 0.7049596591128243, 0.2696652655248289, 0.23888535935569694, 0.3100070039983149, 0.29811774635756455, 0.25894503350611087, 0.24754046593551282, 0.24831404316204567, 0.2843203823323603, 0.20633414056566027, 0.23363461759355333, 0.2654948422202357, 0.26296541977811744, 0.2647558803911562, 0.2628439176413748, 0.31255370654441694]
all_val_score_unet = [0.6751094819899122, 0.7113809255337302, 0.335685138108, 0.7058540401032132, 0.3640736015635578, 0.6734262619241043, 0.7062502890009741, 0.6208602316185495, 0.6339551168845062, 0.6772885596832252, 0.6902976238982572, 0.6901990689056953, 0.6464925006777223, 0.7438483352807302, 0.7080941084138311, 0.668899655969574, 0.6712506383115691, 0.6701367443299469, 0.6717064171038142, 0.6186708732036131]

all_train_loss_unet_pretrained = [0.41557890347935056, 0.289105040801538, 0.24667815682855812, 0.21354566620209733, 0.19513251974775986, 0.17856593127991702, 0.1654017122613417, 0.15709731999684023, 0.15054718649165855, 0.1431809933352712, 0.13808746842315067, 0.13041720665185838, 0.12879718865293102, 0.12282302789390087, 0.12132753474587524, 0.11727521847933531, 0.11677256969080584, 0.11338484088412008, 0.10460511798894889, 0.09906909856441859]
all_val_loss_unet_pretrained = [0.3446367057385268, 0.29267271139003614, 0.29140163571746264, 0.24220325659822534, 0.2170061507710704, 0.20102085752619636, 0.22282832419430768, 0.18902220218269913, 0.17983315719498527, 0.17238431893013142, 0.18239903063685806, 0.23223483479685253, 0.18102957004750217, 0.14659777918347605, 0.19295089471119423, 0.17253253664131518, 0.19748709695758643, 0.15478468244826352, 0.19235073250752907, 0.21280843226446045]
all_val_score_unet_pretrained = [0.701486943603838, 0.7229505373934556, 0.6932783101326108, 0.7312443145200882, 0.7442360376385578, 0.7526037083259723, 0.7141449594658261, 0.7505224080135269, 0.7590210130686055, 0.7656364846556296, 0.7460902411897351, 0.6849745950242864, 0.7430714177655089, 0.7908962431194785, 0.7253571617600352, 0.7499937004546552, 0.7189014222172317, 0.7727530765977567, 0.7259808323365949, 0.7025065003284511]

all_train_loss_unet_plus_pretrained = [0.4495362325294598, 0.2942089245126054, 0.24823065575312925, 0.22269982738873442, 0.198477484587882, 0.18276549684437546, 0.1649224793387426, 0.15729628810407342, 0.14684033484475031, 0.1392704830882517, 0.13375045797107993, 0.1277793640321171, 0.12267302643709085, 0.12027443711318679, 0.116822942990709, 0.10678159719886812, 0.10239290712854347, 0.10087965320594408, 0.09868183070038622, 0.09557261859142296]
all_val_loss_unet_plus_pretrained = [0.3580824064987677, 0.2982573878985864, 0.27700137429767185, 0.2542843829702448, 0.20921880724253478, 0.19894279567179857, 0.19483292158003207, 0.17588027373508172, 0.20814370225977014, 0.20790458884504107, 0.15674628648493025, 0.17725717414308478, 0.18084830128484303, 0.17289670832731105, 0.19542066614936898, 0.15537789436402144, 0.16514960979973828, 0.16482918764706012, 0.16483249184158114, 0.15414481002975394]
all_val_score_unet_plus_pretrained = [0.6958107459622449, 0.7332987227697593, 0.7257380805726816, 0.7274994946226213, 0.7740596973938509, 0.7675202060303442, 0.760847233039152, 0.7799153919733647, 0.7283821096908091, 0.7224731688896185, 0.7900526064966178, 0.7554305395649253, 0.7459857364656031, 0.756123012551885, 0.7248279359987037, 0.77735355346899, 0.7639500364767643, 0.7642194279062624, 0.764423757927934, 0.7782672821469762]

all_train_loss_unet_plus_nopretrained = [0.4570099802033321, 0.35310649589912313, 0.30143180841932427, 0.2610308729313515, 0.23227244877331965, 0.2098272495173119, 0.19528839233759288, 0.1763739667933535, 0.16611309314297662, 0.15331131265171477, 0.14903739165212657, 0.1481581289522551, 0.145709532489245, 0.14340716086932132, 0.1424555650131928, 0.14079611647773432, 0.13993845895134113, 0.13768011205703826, 0.13633150295228572, 0.13576457735050368]
all_val_loss_unet_plus_nopretrained = [0.42295744242491545, 0.3750261498822106, 0.3251262340280745, 0.30876808585944, 0.2584042217996385, 0.24265269383236213, 0.2869122817560478, 0.26097853702527507, 0.23884678300884035, 0.3033869451394788, 0.26026638128139357, 0.28596985229739436, 0.19630058965197317, 0.3082026337031965, 0.22511386650579948, 0.31150291170235034, 0.18537260647173281, 0.2417596545484331, 0.2164876679027522, 0.2019447179304229]
all_val_score_unet_plus_nopretrained = [0.6769640297709313, 0.6793424438975246, 0.7045150535753455, 0.6908522630589837, 0.7320330671402907, 0.7246617539926704, 0.6551257038364057, 0.6740208753433136, 0.693005926724287, 0.6226793323333843, 0.6717341326355544, 0.6406760322550981, 0.7482008951265269, 0.6178634423405441, 0.7115936949376829, 0.6142164705706838, 0.7575018056018145, 0.6888867743507537, 0.7181939593790418, 0.7351101282540617]

all_train_loss_stacking = [0.2971,0.2258, 0.1992, 0.1805, 0.1673, 0.1586, 0.1503, 0.1457, 0.1415, 0.1389, 0.1354, 0.1337, 0.1318, 0.1307, 0.1255]
all_val_loss_stacking = [0.2728, 0.2422, 0.2159, 0.2072, 0.1948, 0.1894, 0.1746, 0.1755, 0.1682, 0.1608, 0.1966, 0.1605, 0.1651, 0.1634, 0.1588]
all_val_score_stacking = [0.7522, 0.7510, 0.7623, 0.7548, 0.7615, 0.7610, 0.7720, 0.7632, 0.7695, 0.7773, 0.7246, 0.7734, 0.7635, 0.7654, 0.7719]

# loss
all_train_loss_bce = [0.4231188313381092, 0.3101089163809209, 0.24876194960764936, 0.2016552844764413, 0.16330696169186282, 0.13591691227378072, 0.11431545834686305, 0.09853735274157009, 0.08534821565892245, 0.07500913135103278, 0.0669376085940245, 0.06038693824430575, 0.05480474304105785, 0.05064771923463087, 0.04711454434672723, 0.04318152619777499, 0.042158374336321615, 0.041437130748621515, 0.040876187761691773, 0.040285117584406525]
all_val_loss_bce = [0.34891260663668316, 0.27800752498485426, 0.2234327241226479, 0.18692982693513235, 0.159197093711959, 0.12902111836053706, 0.11263453242955385, 0.1011662792276453, 0.08625002771064087, 0.0778089416799722, 0.07316892387138473, 0.06832200137001497, 0.05967419663513148, 0.05965816215784461, 0.0577238643610919, 0.05577274080779818, 0.05765254802449986, 0.0562072173450832, 0.05551228837834464, 0.0536302854479463]
all_val_score_bce = [0.6939401574526057, 0.7284424193700129, 0.7271126148802799, 0.7329091970275533, 0.7710431648402137, 0.7687310199646924, 0.7538126019628941, 0.7756649395150355, 0.7595228769437264, 0.7223014035622723, 0.7868584496126386, 0.7572987872246991, 0.751802752816088, 0.7589780122438216, 0.7415713016554258, 0.7776163510313501, 0.7560908073097551, 0.7636530060823946, 0.7661772533707845, 0.7811609353209057]


#lr
all_train_loss_lr_max = [0.2673770060410371, 0.18230563019578522, 0.17037853341851686, 0.15986739932181868, 0.1550011084339506, 0.1483452155733028, 0.14698583542092428, 0.1332693179515568, 0.12966581421426018, 0.12823104120891643, 0.12629143863513664]
all_val_loss_lr_max = [0.2363146891196569, 1.3564216522154984, 0.19024505549006993, 1.080664357929318, 0.3582043300072352, 0.7486409161377836, 0.34179430841295805, 0.19053522607794515, 0.20253826043120138, 0.18389716772017656, 0.15169550975163779]
all_val_score_lr_max = [0.6944204934414585, 0.2512222131682838, 0.7250417093210136, 0.27386657873974435, 0.5488751747250342, 0.3470920668607545, 0.5691100502319943, 0.7199027080114995, 0.7065399096978298, 0.7284960985418417, 0.7705902345529211]

all_train_loss_lr_min = [0.7150752904850084, 0.4295716597824483, 0.3850812172970256, 0.3570043436578802, 0.33814559131860733, 0.32762250676751137, 0.3162774697348878, 0.3059832005686051, 0.29962928703910596, 0.28974674913931536]
all_val_loss_lr_min = [0.482127473310188, 0.44829437467787003, 0.41010262899928623, 0.3761374646866763, 0.3891192884356887, 0.3492752539890784, 0.34772144589159226, 0.3199466969128008, 0.324159625503752, 0.3168517820261143]
all_val_score_lr_min = [0.5952433203065836, 0.6171307337291838, 0.6512836225215709, 0.6874058758934143, 0.6652895258154752, 0.7101800146252886, 0.7062544759980915, 0.742040619010452, 0.7295916429203947, 0.7326011771951535]

# sgd
all_train_loss_sgd = [0.9125988495510977, 0.6260633512928679, 0.6451447535608266, 0.2755104224323421, 0.21839976985309575, 0.2021257702160526, 0.19303732556668488, 0.18633683373195095, 0.1799879013183149, 0.17464787462675893]
all_val_loss_sgd = [0.5526315327043887, 0.8203549870738277, 0.4854259733800535, 0.249127346056479, 0.25376938228253965, 0.24408365896454565, 0.21095466255037873, 0.2413505130895862, 0.2365869634129383, 0.24777524476801907]
all_val_score_sgd = [0.46145766288941037, 0.15266223819396063, 0.3966281963852997, 0.6540965695907557, 0.6496115596027541, 0.6593037308503362, 0.696160243347785, 0.6619468847846349, 0.6672495119750042, 0.6577548329378364]

# optim
plt.figure()
plt.title('jaccard score')
plt.plot(all_val_score_sgd, color='r', label='sgd')
plt.plot(all_val_score_unet_pretrained[0:10], color='y', label='adam')
plt.legend()
plt.xlabel('epoch')
plt.ylabel('val js')
plt.show()
# lr
plt.figure()
plt.title('jaccard score')
plt.plot(all_val_score_unet_pretrained[0:10], color='r', label='lr=0.0001')
plt.plot(all_val_score_lr_max[0:10], color='y', label='lr=0.001')
plt.plot(all_val_score_lr_min, color='b', label='lr=0.00001')
plt.legend()
plt.xlabel('epoch')
plt.ylabel('val js')
plt.show()

# loss
plt.figure()
plt.title('jaccard score')
plt.plot(all_val_score_unet_plus_pretrained, color='r', label='loss=bce dice')
plt.plot(all_val_score_bce, color='b', label='loss=bce')
plt.legend()
plt.xlabel('epoch')
plt.ylabel('val js')
plt.show()


plt.figure()
plt.title('train loss')
plt.plot(all_train_loss_unet, color='y', label='U-Net')
plt.plot(all_train_loss_unet_pretrained, color='r', label='U-Net/Pretrained')
plt.plot(all_train_loss_unet_plus_nopretrained, color='b', label='U-Net++')
plt.plot(all_train_loss_unet_plus_pretrained, color='g', label='U-Net++/Pretrained')
plt.plot(all_train_loss_stacking, color='purple', label='U-Net/Stacking')
plt.legend()
plt.xlabel('epoch')
plt.ylabel('train loss')
plt.show()

plt.figure()
plt.title('validation loss')
plt.plot(all_val_loss_unet, color='y', label='U-Net')
plt.plot(all_val_loss_unet_pretrained, color='r', label='U-Net/Pretrained')
plt.plot(all_val_loss_unet_plus_nopretrained, color='b', label='U-Net++')
plt.plot(all_val_loss_unet_plus_pretrained, color='g', label='U-Net++/Pretrained')
plt.plot(all_val_loss_stacking, color='purple', label='U-Net/Stacking')
plt.legend()
plt.xlabel('epoch')
plt.ylabel('val loss')
plt.show()

plt.figure()
plt.title('validation jaccard score')
plt.plot(all_val_score_unet, color='y', label='U-Net')
plt.plot(all_val_score_unet_pretrained, color='r', label='U-Net/Pretrained')
plt.plot(all_val_score_unet_plus_nopretrained, color='b', label='U-Net++')
plt.plot(all_val_score_unet_plus_pretrained, color='g', label='U-Net++/Pretrained')
plt.plot(all_val_score_stacking, color='purple', label='U-Net/Stacking')
plt.legend()
plt.xlabel('epoch')
plt.ylabel('val js')
plt.show()

print('U-Net',max(all_val_score_unet))
print('U-Net/Pretrained', max(all_val_score_unet_pretrained))
print('U-Net++', max(all_val_score_unet_plus_nopretrained))
print('U-Net++/Pretrained', max(all_val_score_unet_plus_pretrained))
print('U-Net/Stacking', max(all_val_score_stacking))

# dataset2
train_loss = [0.3614,0.2312,0.1946,0.1700,0.1520,0.1358,0.1274,0.1187,0.1124,0.1110]
val_loss = [0.2665,0.2081,0.2151,0.1779,0.1731,0.1557,0.1397,0.1383,0.1219,0.1195]
val_js = [0.7914,0.8238,0.7919,0.8212,0.8169,0.8263,0.8303,0.8310,0.8382,0.8404]
plt.figure()
plt.title('loss')
plt.plot(train_loss, color='y', label='train')
plt.plot(val_loss, color='r', label='val')
plt.legend()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()

plt.figure()
plt.title('validation jaccard score')
plt.plot(val_js, color='y', label='val js')
plt.legend()
plt.xlabel('epoch')
plt.ylabel('val js')
plt.show()